# -*- coding: utf-8 -*-
"""THYROID CLASSIFICATION PROJECT

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jcFubpMGRuYZttiQnDMPocK2s6xfovyL
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier, GradientBoostingRegressor
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import f1_score
from sklearn.metrics import classification_report,confusion_matrix
import warnings
import pickle
from scipy import stats

df=pd.read_csv('/content/drug200.csv')

df

df.shape

# Checking Nulls

df.isnull().sum()

# Descriptive Analysis

df.describe()

df.info()

df[df.Age>100]

# changing age of observation with(age>100) to null
df['Age']=np.where((df.Age>100),np.nan,df.Age)

df

df['Drug'].value_counts()

from sklearn.preprocessing import LabelEncoder

le=LabelEncoder()
df['Sex']=le.fit_transform(df['Sex'])
le1=LabelEncoder()
df['BP']=le1.fit_transform(df['BP'])
le2=LabelEncoder()
df['Cholesterol']=le2.fit_transform(df['Cholesterol'])

le3=LabelEncoder()

df['Drug']=le3.fit_transform(df['Drug'])

df.info()

"""DrugY    91
drugX    54
drugA    23
drugC    16
drugB    16
"""

df['Drug'].value_counts()

# splitting the data values as x and y
x=df.iloc[:,0:-1]
y=df.iloc[:,-1]

x

y

x['Sex'].unique()

x['Sex'].replace(np.nan,'F',inplace=True)

x['Sex'].value_counts()

x.info()

#Encoding the categorical data
#Encoding the independent (output) variable
from sklearn.preprocessing import OrdinalEncoder
#categorical data

ordinal_encoder=OrdinalEncoder(dtype='int64')
x.iloc[:,1:16]=ordinal_encoder.fit_transform(x.iloc[:,1:16])
#ordinal_encoder.fit_transform[x[['Sex]]]

x

label_encoder=LabelEncoder()
y_dt=label_encoder.fit_transform(y)

y=pd.DataFrame(y_dt,columns=['target'])

y

#checking correlation using Heatmap
corrmat=x.corr()
f,ax=plt.subplots(figsize=(9,8))
sns.heatmap(corrmat,ax=ax,cmap="YlGnBu",linewidths=0.1)

"""Not more than 50% correlation amongnst columns"""

# splitting the data values as x and y
x=df.iloc[:,0:-1]
y=df.iloc[:,-1]

x

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=12)

from imblearn.over_sampling import SMOTE
y_train.value_counts()

os = SMOTE(random_state=0,k_neighbors=1)
x_bal,y_bal=os.fit_resample(x_train,y_train)
x_test_bal,y_test_bal=os.fit_resample(x_test,y_test)

from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
x_bal=sc.fit_transform(x_bal)
x_test_bal=sc.transform(x_test_bal)

x_bal

columns=['Age','Sex','BP','Cholesterol','Na_to_K']

x_test_bal=pd.DataFrame(x_test_bal,columns=columns)

x_bal=pd.DataFrame(x_bal,columns=columns)

x_bal

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score,classification_report
rfr = RandomForestClassifier().fit(x_bal,y_bal)
y_pred = rfr.predict(x_test_bal)
accuracy_score(y_test_bal,y_pred)
x_bal.shape,y_bal.shape,x_test_bal.shape,y_test_bal.shape

test_score=accuracy_score(y_test_bal,y_pred)

test_score

"""The model is 95% accurate"""

train_score=accuracy_score(y_bal,rfr.predict(x_bal))
train_score

#perform feature importance
from sklearn.inspection import permutation_importance
results=permutation_importance(rfr,x_bal,y_bal,scoring='accuracy')

#gets importance
feature_importance=['Age','Sex','BP','Cholesterol','Na_to_K']
importance=results.importances_mean
importance=np.sort(importance)
#summerize feature importance
for i,v in enumerate(importance):
  i=feature_importance[i]
  print('feature:{:<20} Score: {}'.format(i,v))
#plot important feature
plt.figure(figsize=(10,10))
plt.bar(x=feature_importance,height=importance)
plt.xticks(rotation=30,ha='right')
plt.show()

"""Feature Na_to_K is most important"""

x.head()

x_bal.drop('Sex',axis=1,inplace=True)

x_bal.drop('Age',axis=1,inplace=True)

x_test_bal.drop('Sex',axis=1,inplace=True)

x_test_bal.drop('Age',axis=1,inplace=True)

x_bal.head()

"""Since feature importance has low scores for age and sex we are considering these columns as unimportant for output variable"""

rfr1=RandomForestClassifier().fit(x_bal,y_bal.values.ravel())
rfr1=RandomForestClassifier()

rfr1.fit(x_bal,y_bal.values.ravel())

y_pred=rfr1.predict(x_test_bal)

print(classification_report(y_test_bal,y_pred))

train_score=accuracy_score(y_bal,rfr1.predict(x_bal))
train_score

from xgboost import XGBClassifier
xgb1=XGBClassifier()
xgb1.fit(x_bal,y_bal)

y_pred=xgb1.predict(x_test_bal)

print(classification_report(y_test_bal,y_pred))

accuracy_score(y_test_bal,y_pred)

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report

sv=SVC()

sv.fit(x_bal,y_bal)

y_pred=sv.predict(x_test_bal)

print(classification_report(y_test_bal,y_pred))

train_score=accuracy_score(y_bal,sv.predict(x_bal))
train_score

params={
    'C':[0.1,1,10,100,1000],
    'gamma':[1,0.1,0.01,0.001,0.0001],
        'kernel':['rbf','sqrt']
}

from sklearn.model_selection import RandomizedSearchCV
random_svc=RandomizedSearchCV(sv,params,scoring='accuracy',cv=5,n_jobs=-1)

random_svc.fit(x_bal,y_bal)

random_svc.best_params_

"""{'kernel': 'rbf', 'gamma': 1, 'C': 100}"""

sv1=SVC(kernel='rbf',gamma=0.1,C=100)

sv1.fit(x_bal,y_bal)

y_pred=sv1.predict(x_test_bal)

print(classification_report(y_test_bal,y_pred))

train_score=accuracy_score(y_bal,sv1.predict(x_bal))
train_score

#saving the model
import pickle
pickle.dump(sv1,open('thyroid_1_model.pkl','wb'))

features = np.array([[0.35,1.0,1.5]])
print(label_encoder.inverse_transform(xgb1.predict(features)))

pickle.dump(label_encoder,open('label_encoder.pkl','wb'))

df['Drug'].unique()

"""DrugY-0-91,
drugX-4-54,
drugA-1-23,
drugC-3-16,
drugB-2-16.
"""

y.unique()